{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import os\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Load your data\n",
    "file_path = 'dataset.csv'  # Replace with the correct file path\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Print the column names to understand their format\n",
    "print(data.columns)\n",
    "\n",
    "# Ensure the columns are strings before removing degree symbols\n",
    "data['Rx_θr'] = data['Rx_θr'].astype(str).str.replace('°', '').astype(float)\n",
    "data['Rx_Φr'] = data['Rx_Φr'].astype(str).str.replace('°', '').astype(float)\n",
    "data['RIS_θₙ'] = data['RIS_θₙ'].astype(str).str.replace('°', '').astype(float)\n",
    "data['RIS_Φₙ'] = data['RIS_Φₙ'].astype(str).str.replace('°', '').astype(float)\n",
    "\n",
    "# Extract only the angle columns\n",
    "angle_columns = [col for col in data.columns if 'θᵣ=' in col]\n",
    "angles = [float(col.split('=')[1]) for col in angle_columns]\n",
    "angles_rad = np.radians(angles)\n",
    "\n",
    "# Extract azimuth and elevation angles for the receiver\n",
    "receiver_angles = data[['Rx_θr', 'Rx_Φr']].values.astype(np.float32)\n",
    "\n",
    "# Extract beam angles\n",
    "beam_angles = data[['RIS_θₙ', 'RIS_Φₙ']].values.astype(np.float32)\n",
    "\n",
    "# Normalize the data if necessary\n",
    "data_normalized = (data[angle_columns] - data[angle_columns].mean()) / data[angle_columns].std()\n",
    "\n",
    "# Combine receiver angles and beam angles with the normalized data\n",
    "X = np.hstack((receiver_angles, beam_angles, data_normalized.values.astype(np.float32)))\n",
    "y = data_normalized.values.astype(np.float32)  # For this example, we'll use the same data as targets\n",
    "\n",
    "# Print shapes to verify\n",
    "print(f'X shape: {X.shape}')\n",
    "print(f'y shape: {y.shape}')\n",
    "\n",
    "# Reshape X to include a sequence dimension\n",
    "seq_length = 1  # Assuming each sample is a sequence of length 1\n",
    "X_reshaped = X.reshape((X.shape[0], seq_length, X.shape[1]))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X_reshaped, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, seq_length, dropout_rate=0.2):\n",
    "        super(CNNModel, self).__init__()\n",
    "\n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "\n",
    "        # Layer normalization\n",
    "        self.layer_norm = nn.LayerNorm(128)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Dummy input to calculate fc_input_size\n",
    "        dummy_input = torch.rand(1, input_dim, seq_length)\n",
    "        dummy_output = self.conv2(self.conv1(dummy_input))\n",
    "        self.fc_input_size = dummy_output.view(dummy_output.size(0), -1).size(1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, output_dim)\n",
    "\n",
    "        # Activation\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, in_channels, seq_length)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, seq_length, in_channels)\n",
    "        x = self.layer_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# k-Fold Cross-Validation\n",
    "k = 5\n",
    "kfold = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store the history of losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_maes = []\n",
    "val_maes = []\n",
    "train_rmses = []\n",
    "val_rmses = []\n",
    "train_mses = []\n",
    "val_mses = []\n",
    "\n",
    "# DataFrame to store evaluation metrics\n",
    "evaluation_df = pd.DataFrame(columns=['Fold', 'Epoch', 'Train Loss', 'Val Loss', 'Train MAE', 'Val MAE', 'Train RMSE', 'Val RMSE', 'Train MSE', 'Val MSE'])\n",
    "\n",
    "# Create a directory to save the plots\n",
    "output_dir = 'beam_pattern_plots_combined_20'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "for fold, (train_ids, val_ids) in enumerate(kfold.split(X_tensor)):\n",
    "    print(f'Fold {fold + 1}')\n",
    "    # Split the data into training and validation sets\n",
    "    X_train, X_val = X_tensor[train_ids], X_tensor[val_ids]\n",
    "    y_train, y_val = y_tensor[train_ids], y_tensor[val_ids]\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    model = CNNModel(input_dim=X_tensor.shape[2], output_dim=y_tensor.shape[1], seq_length=seq_length, dropout_rate=0.2)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "    # Lists to store the history of losses for this fold\n",
    "    fold_train_losses = []\n",
    "    fold_val_losses = []\n",
    "    fold_train_maes = []\n",
    "    fold_val_maes = []\n",
    "    fold_train_rmses = []\n",
    "    fold_val_rmses = []\n",
    "    fold_train_mses = []\n",
    "    fold_val_mses = []\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 300\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate training loss, MAE, RMSE, and MSE\n",
    "        train_loss = loss.item()\n",
    "        train_mae = mean_absolute_error(y_train.detach().numpy(), outputs.detach().numpy())\n",
    "        train_rmse = np.sqrt(mean_squared_error(y_train.detach().numpy(), outputs.detach().numpy()))\n",
    "        train_mse = mean_squared_error(y_train.detach().numpy(), outputs.detach().numpy())\n",
    "\n",
    "        # Calculate validation loss, MAE, RMSE, and MSE\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss = criterion(val_outputs, y_val).item()\n",
    "            val_mae = mean_absolute_error(y_val.detach().numpy(), val_outputs.detach().numpy())\n",
    "            val_rmse = np.sqrt(mean_squared_error(y_val.detach().numpy(), val_outputs.detach().numpy()))\n",
    "            val_mse = mean_squared_error(y_val.detach().numpy(), val_outputs.detach().numpy())\n",
    "\n",
    "        # Store the losses for this epoch\n",
    "        fold_train_losses.append(train_loss)\n",
    "        fold_val_losses.append(val_loss)\n",
    "        fold_train_maes.append(train_mae)\n",
    "        fold_val_maes.append(val_mae)\n",
    "        fold_train_rmses.append(train_rmse)\n",
    "        fold_val_rmses.append(val_rmse)\n",
    "        fold_train_mses.append(train_mse)\n",
    "        fold_val_mses.append(val_mse)\n",
    "\n",
    "        # Append the evaluation metrics to the DataFrame\n",
    "        evaluation_df = pd.concat([evaluation_df, pd.DataFrame({\n",
    "            'Fold': fold + 1,\n",
    "            'Epoch': epoch + 1,\n",
    "            'Train Loss': train_loss,\n",
    "            'Val Loss': val_loss,\n",
    "            'Train MAE': train_mae,\n",
    "            'Val MAE': val_mae,\n",
    "            'Train RMSE': train_rmse,\n",
    "            'Val RMSE': val_rmse,\n",
    "            'Train MSE': train_mse,\n",
    "            'Val MSE': val_mse\n",
    "        }, index=[0])], ignore_index=True)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train MAE: {train_mae:.4f}, Val MAE: {val_mae:.4f}, Train RMSE: {train_rmse:.4f}, Val RMSE: {val_rmse:.4f}, Train MSE: {train_mse:.4f}, Val MSE: {val_mse:.4f}')\n",
    "\n",
    "    # Store the losses for this fold\n",
    "    train_losses.append(fold_train_losses)\n",
    "    val_losses.append(fold_val_losses)\n",
    "    train_maes.append(fold_train_maes)\n",
    "    val_maes.append(fold_val_maes)\n",
    "    train_rmses.append(fold_train_rmses)\n",
    "    val_rmses.append(fold_val_rmses)\n",
    "    train_mses.append(fold_train_mses)\n",
    "    val_mses.append(fold_val_mses)\n",
    "\n",
    "# Calculate the average losses across all folds\n",
    "avg_train_losses = np.mean(train_losses, axis=0)\n",
    "avg_val_losses = np.mean(val_losses, axis=0)\n",
    "avg_train_maes = np.mean(train_maes, axis=0)\n",
    "avg_val_maes = np.mean(val_maes, axis=0)\n",
    "avg_train_rmses = np.mean(train_rmses, axis=0)\n",
    "avg_val_rmses = np.mean(val_rmses, axis=0)\n",
    "avg_train_mses = np.mean(train_mses, axis=0)\n",
    "avg_val_mses = np.mean(val_mses, axis=0)\n",
    "\n",
    "# Plot training vs. validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_train_losses, label='Training Loss')\n",
    "plt.plot(avg_val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training vs. Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir, 'training_vs_validation_loss.png'))\n",
    "plt.show()\n",
    "\n",
    "# Plot training vs. validation MAE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_train_maes, label='Training MAE')\n",
    "plt.plot(avg_val_maes, label='Validation MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error')\n",
    "plt.title('Training vs. Validation MAE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir, 'training_vs_validation_mae.png'))\n",
    "plt.show()\n",
    "\n",
    "# Plot training vs. validation RMSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_train_rmses, label='Training RMSE')\n",
    "plt.plot(avg_val_rmses, label='Validation RMSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Root Mean Squared Error')\n",
    "plt.title('Training vs. Validation RMSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir, 'training_vs_validation_rmse.png'))\n",
    "plt.show()\n",
    "\n",
    "# Plot training vs. validation MSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(avg_train_mses, label='Training MSE')\n",
    "plt.plot(avg_val_mses, label='Validation MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Training vs. Validation MSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir, 'training_vs_validation_mse.png'))\n",
    "plt.show()\n",
    "\n",
    "# Save the evaluation metrics to a CSV file\n",
    "evaluation_df.to_csv(os.path.join(output_dir, 'evaluation_metrics.csv'), index=False)\n",
    "\n",
    "# Make predictions on the test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_tensor).numpy()\n",
    "\n",
    "# Check shapes\n",
    "print(f'y_test shape: {y_tensor.shape}')\n",
    "print(f'predictions shape: {predictions.shape}')\n",
    "print(f'angles_rad shape: {len(angles_rad)}')\n",
    "'''\n",
    "# Visualize the predictions for all test samples\n",
    "for i in range(len(y_tensor)):  # Visualize all predictions\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    ax.plot(angles_rad, y_tensor[i].numpy(), label='Measurement')\n",
    "    ax.plot(angles_rad, predictions[i], label='DNN Model', linestyle='--')\n",
    "    ax.fill(angles_rad, y_tensor[i].numpy(), alpha=0.3)  # Optional: fill under the true curve\n",
    "    ax.fill(angles_rad, predictions[i], alpha=0.3)  # Optional: fill under the predicted curve\n",
    "\n",
    "    # Add receiver location\n",
    "    rx_theta = np.radians(X_tensor[i][0][0].item())\n",
    "    rx_phi = X_tensor[i][0][1].item()  # Elevation angle in degrees\n",
    "    ax.plot(rx_theta, 1, 'ro', markersize=10, label='Receiver')  # Mark the receiver location\n",
    "\n",
    "    # Add beam angles to the title\n",
    "    ris_theta = X_tensor[i][0][2].item()\n",
    "    ris_phi = X_tensor[i][0][3].item()\n",
    "    ax.set_title(f\"Beam Pattern Prediction\\nRx_θr: {X_tensor[i][0][0].item():.2f}°, Rx_Φr: {X_tensor[i][0][1].item():.2f}°\\nRIS_θₙ: {ris_theta:.2f}°, RIS_Φₙ: {ris_phi:.2f}°\", va='bottom', fontsize=14)\n",
    "    plt.legend(loc=\"upper right\", bbox_to_anchor=(1.1, 1.1), title=\"Legend\")\n",
    "\n",
    "    # Save the plot to a file\n",
    "    plot_filename = os.path.join(output_dir, f'beam_pattern_{i}.png')\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "'''\n",
    "print(f'Plots saved to {output_dir}')\n",
    "\n",
    "## Define a wrapper function for the model\n",
    "#def model_predict(X):\n",
    "#    model.eval()\n",
    "#    with torch.no_grad():\n",
    "#        return model(torch.tensor(X, dtype=torch.float32)).numpy()\n",
    "#\n",
    "## Use a smaller subset of the data for SHAP explanations\n",
    "#X_shap = X_tensor[:100].numpy()\n",
    "#\n",
    "## SHAP values\n",
    "#explainer = shap.Explainer(model_predict, X_shap)\n",
    "#shap_values = explainer(X_shap)\n",
    "#\n",
    "## Plot SHAP values\n",
    "#feature_names = ['Rx_θr', 'Rx_Φr', 'RIS_θₙ', 'RIS_Φₙ'] + angle_columns\n",
    "#shap.summary_plot(shap_values, X_shap, feature_names=feature_names)\n",
    "#plt.savefig(os.path.join(output_dir, 'shap_summary.png'))\n",
    "#plt.show()\n",
    "\n",
    "# Save MSE and other evaluation parameters in a separate CSV file\n",
    "mse_df = pd.DataFrame({\n",
    "    'Fold': evaluation_df['Fold'].unique(),\n",
    "    'Train MSE': [np.mean(fold_train_mses) for fold_train_mses in train_mses],\n",
    "    'Val MSE': [np.mean(fold_val_mses) for fold_val_mses in val_mses]\n",
    "})\n",
    "mse_df.to_csv(os.path.join(output_dir, 'mse_evaluation_metrics.csv'), index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
